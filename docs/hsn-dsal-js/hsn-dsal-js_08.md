# 第八章：大 O 符号、空间和时间复杂度

在前几章中，我们经常谈到优化我们的代码/算法，并简要使用了空间和时间复杂度这些术语，以及我们希望将它们降到最低。顾名思义，我们希望将代码的复杂性保持在最低，但这意味着什么？这种复杂性有不同的级别吗？我们如何计算算法的空间和时间复杂度？这些是我们将在本章讨论的问题，同时讨论以下主题：

+   不同程度的时间复杂度

+   空间复杂度和辅助空间

# 术语

讨论算法的空间和时间复杂度时使用的术语是开发人员经常会遇到的。流行的术语，如**大 O 符号**，也被称为**O（something）**，以及一些不那么流行的术语，如**Omega（something）**或**Theta（something）**经常用来描述算法的复杂性。O 实际上代表 Order，表示函数的阶数。

让我们首先只讨论算法的时间复杂度。基本上，这归结为我们试图弄清楚系统在给定数据集（D）上执行我们的算法需要多长时间。我们可以在所述系统上运行此算法并记录其性能，但由于并非所有系统都相同（例如，操作系统、处理器数量和读写速度），我们不能期望结果真正代表执行我们的算法所需的平均时间。同时，我们还需要知道我们的算法在数据集 D 的大小变化时的表现。它对于 10 个元素和 1000 个元素需要相同的时间吗？还是花费的时间呈指数增长？

有了上述所有内容，我们如何清楚地理解算法的复杂性呢？我们通过将算法分解为一组基本操作，然后将它们组合起来，得到每个操作的总体数量/复杂度。这真正定义了算法的时间复杂度，即随着输入数据集 D 的大小增长而增长的时间速率。

现在，为了以抽象的方式计算时间复杂度，让我们假设我们有一台机器，它需要一个单位的时间来执行一些基本操作，比如读取、写入、赋值、算术和逻辑计算。

说到这里，让我们来看一个简单的函数，它返回给定数字的平方：

```js
function square(num) {
    return num*num;
}
```

我们已经定义了我们的机器，它消耗一个单位的时间来执行乘法，另一个单位来返回结果。不考虑输入，我们的算法总是只需要 2 个单位的时间，因为这不会改变，所以被称为常数时间算法。这里所花费的常数时间是 k 个时间单位并不重要。我们可以将所有类似的函数表示为`O(1)`或`big-O(1)`的一组函数，这些函数执行需要恒定的时间。

让我们再举一个例子，我们循环遍历一个大小为 n 的列表，并将每个元素乘以一个因子：

```js
function double(array) {
    for(var i = 0; i <  array.length; i++) {
        array[i] *= 2;
    }

    return array;
}
```

要计算这个函数的时间复杂度，我们首先需要计算这个函数中每个语句的执行成本。

第一条语句在中断之前执行*n+1*次，并且每次执行时，增加 1 个单位的成本和进行比较检查等其他操作也需要 1 个单位的成本。换句话说，我们可以假设每次迭代中花费了*C*[1]个时间单位，因此下面这行代码的总成本是*C[1]*(n+1)*：

```js
for(var i = 0; i <  array.length; i++) {
```

在下一条语句中，我们将数组中给定索引处的值乘以 2。由于这是在循环内部，这条语句执行了 n 次，每次执行时，我们假设它花费了*C[2]*个单位。因此，这行代码的总执行成本将是*C[2]*n*：

```js
array[i] *= 2;
```

然后，我们最终有返回语句，它也需要花费一个常数的时间—*C[3]*—来将最终的数组返回给调用者。将所有这些成本加在一起，我们得到方法的总成本如下：

```js
Tdouble = C1*(n + 1) + C2* n + C3;
        = C5 * n + C4 // where C4 = C3 + C1 and C5 = C1 + C2
```

我们可以看到，在这种情况下，方法的成本与输入数组的大小`N`成正比。因此，这组函数可以用`O(n)`表示，表明它们与输入大小成正比。

然而，在我们跳到更多的例子之前，让我们先看看如何在没有所有计算的情况下表示复杂度。

# 渐近符号

当我们想要推导和比较两个或更多算法的时间复杂度时，渐近符号非常有用。渐近符号的意思是，一旦我们计算出一个算法的时间复杂度，我们只需要用一个非常大的数（趋向于无穷大）来替换*n*（我们算法的输入大小），然后去掉方程中的常数。这样做会让我们留下真正影响我们执行时间的唯一因素。

让我们拿和前面部分相同的例子：

```js
Tdouble = C1*(n + 1) + C2* n + C3;
        = C5 * n + C4 // where C4 = C3 + C1 and C5 = C1 + C2
```

当我们应用刚刚描述的关于渐近符号的规则时，即*n -> 无穷大*，我们很快就能看到`C[4]`的影响相当微不足道，可以忽略不计。我们也可以说相同的事情适用于乘法因子`C[5]`。我们得到的是这一次，`T[double]`与输入数组的大小`(n)`成正比，因此我们能够用`O(n)`符号表示这一点，因为在这种情况下，大小 n 是唯一重要的变量。

有三种主要类型的渐近符号，可以用来对算法的运行时间进行分类：

+   **Big-O**：表示运行时间增长率的上界

+   **Omega**：表示运行时间增长率的下界

+   **Theta**：表示运行时间增长率的紧密界限

# 大 O 符号

假设我们有一个`f(n)`方法，我们想用一个时间复杂度函数（即一个集合）`g(n)`来表示：

当且仅当存在常数 c 和 n[0]，使得`f(n) <= cg(n)`，且输入大小`n >= n[0]`时，`f(n)`是`O(g(n))`。

现在，让我们尝试将这个应用到我们之前的例子中：

```js
f(n) = Tdouble = C5 * n + C4 
f(n) = Tdouble = 4n + 1 // cause C5 and C4 can be any constants
```

对于这个例子，我们用集合`O(n)`表示它，也就是`g(n) = n`。

为了使我们的时间复杂度断言成立，我们需要满足以下条件：

```js
4n + 1 <= c * n , where n >= n0
```

这个方程对于`c = 5`和`n[0] = 1`的值是满足的。另外，由于定义得到满足，我们可以安全地说`f(n)`函数是`big-O(g(n))`，也就是`O(g(n))`，或者在这种情况下是`O(n)`。我们也可以在图表上看到这一点，如下图所示；在`n = 1`之后，我们可以看到`c * g(n)`的值在渐近上始终大于`f(n)`的值。看一下下面的图表：

![](img/bf044bdb-d2b6-4447-b244-932702ba8e11.png)

# Omega 符号

类似于之前讨论的大 O 符号，Omega 符号表示算法运行时间的增长率的下界。因此，如果我们有一个`f(n)`方法，我们想用一个时间复杂度函数（即一个集合）`g(n)`来表示，那么 Omega 符号可以定义如下：

当且仅当存在常数 c 和 n[0]，使得`f(n) >= cg(n)`，其中输入大小`n >= n[0]`时，`f(n)`是`O(g(n))`。

采用和前面部分相同的例子，我们有`f(n) = 4n + 1`，然后`g(n) = n`。我们需要验证存在 c 和 n[0]，使得前面的条件成立，如下面的片段所示：

```js
4n + 1 >= c * n , where n >= n0 
```

我们可以看到这个条件对于`c = 4`和`n[0] = 0`是成立的。因此，我们可以说我们的函数`f(n)`是`Ω(n)`。我们也可以在图表上表示这一点，看一下它如何表示我们的函数`f(n)`以及它的上界和下界：

![](img/70c13bfd-ef7e-4149-bf2f-c75c67e23ac2.png)

从前面的图表中，我们可以看到我们的函数`f(n)`（黑色）位于渐近上限和下限（灰色）之间。*x*轴表示大小（*n*）的值。

# θ符号

计算了函数`f(n)`的增长率的上限和下限之后，我们现在也可以确定函数`f(n)`的紧密边界或θ。因此，如果我们有一个`f(n)`方法，我们想用时间复杂度函数（也称为集合）`g(n)`来表示，那么函数的紧密边界可以定义如下：

如果`f(n)`是 O(g(n))，当且仅当存在常数 c 和 n[0]，使得 c[1]g(n) <= f(n) <= c[2]g(n)，其中输入大小 n >= n[0]

前两节的操作已经计算了我们的函数，即`f(n) = 4n + 1`：`c[1] = 4`，`c[2] = 5`，`n[0] = 1`。

这为我们提供了函数`f(n)`的紧密边界，由于函数始终在`n = 1`之后的紧密边界内，我们可以安全地说我们的函数 f(n)具有紧密的增长率，即`θ(n)`。

# 回顾

在继续下一个主题之前，让我们快速回顾一下我们讨论的不同类型的符号：

+   `O`表示`f(n)`的增长率渐近小于或等于*g(n)*的增长率

+   `Ω`表示`f(n)`的增长率渐近大于或等于*g(n)*的增长率

+   `θ`表示`f(n)`的增长率渐近等于`g(n)`的增长率

# 时间复杂度的例子

现在让我们检查一些时间复杂度计算的例子，因为在 99%的情况下，我们需要知道函数可能执行的最长时间；我们将主要分析最坏情况时间复杂度，即基于函数输入的增长率的上限。

# 常数时间

常数时间函数是指执行时间不受传入函数的大小的影响：

```js
function square(num) {
    return num*num;
}
```

前面的代码片段是一个常数时间函数的例子，用 O(1)表示。常数时间算法是最受追捧的算法，因为它们无论输入的大小如何都在恒定时间内运行。

# 对数时间

对数时间函数是指执行时间与输入大小的对数成比例。考虑以下例子：

```js
for(var i = 1; i < N; i *= 2) {
    // O(1) operations
}
```

我们可以看到，在任何给定的迭代中，*i = 2^i*，因此在第*n*次迭代中，*i = 2^n*。此外，我们知道*i*的值始终小于循环本身的大小(*N*)。由此，我们可以推断出以下结果：

```js
2n < N

log(2n) < log(N)

n < log(N) 
```

从前面的代码中，我们可以看到迭代次数始终小于输入大小的对数。因此，这样的算法的最坏情况时间复杂度将是`O(log(n))`。

让我们考虑另一个例子，下一次迭代将`i`的值减半：

```js
for(var i = N; i >= 1; i /= 2) {
    // O(1) operations
}
```

在第`n`次迭代中，`i`的值将为`N/2^n`，我们知道循环以值`1`结束。因此，为了使循环停止，`i`的值需要`<= 1`；现在，通过结合这两个条件，我们得到以下结果：

```js
N/2n <= 1

N <= 2n

Log(N) <= n
```

我们可以得出与第一个例子类似的结论，即迭代次数始终小于输入大小或值的对数值。

需要注意的一点是，这不仅限于加倍或减半现象。这可以应用于任何算法，其中步骤的数量被因子`k`减少。这类算法的最坏情况时间复杂度将是`O(logk)`，在我们的前面的例子中，`k`恰好是`2`。

对数时间复杂度算法是下一个受欢迎的，因为它们以对数方式消耗时间。即使输入的大小翻倍，算法的运行时间也只会增加一个小的数（这是对数的定义）。

# 线性时间

现在让我们讨论最常见的时间复杂度之一，线性时间。可以猜到，方法的线性时间复杂度表示该方法执行需要线性时间：

```js
for(var i = 0; i < N; i += c) {
    // O(1) operations
}
```

这是一个非常基本的`for`循环，我们在其中执行一些常数时间的操作。随着 N 的大小增加，循环执行的次数也会增加。

正如你所看到的，在每次迭代中，`i`的值都会增加一个常数`c`，而不是`1`。这是因为增量是什么并不重要，只要它们是线性的。

在第一次迭代中，`i = 0`；在第二次迭代中，`i = c`，然后在第三次迭代中是`c + c = 2c`，在第四次迭代中是`3c`，依此类推。因此，在第 n 次迭代中，我们有`i = c(n-1)`的值，渐近地是`O(n)`。

根据你的用例是什么，线性时间复杂度可能是好的，也可能不是。这有点是灰色地带，如果你不确定是否需要进一步优化，有时可能会放弃。

# 二次时间

随着二次时间复杂度算法，我们现在进入了时间复杂度的黑暗面。顾名思义，输入的大小会二次影响算法的运行时间。一个常见的例子是嵌套循环：

```js
for (int i = 0; i <n; i += c) {
    for (int j = 0; j < n; j += c) {
        // some O(1) expressions
    }
}
```

正如前面的例子所示，对于`i = 0`，内部循环运行*n*次，对于`i = 1`，`i = 2`，依此类推。内部循环总是运行 n 次，不依赖于 n 的值，因此使得算法的时间复杂度为`O(n²)`。

# 多项式时间

多项式时间复杂度是算法的运行时间复杂度，其顺序为`n^k`。二次时间复杂度算法是多项式时间算法的某种类型，其中`k = 2`。这样的算法的一个非常简单的例子如下：

```js
for (int i = 0; i <n; i += c) {
    for (int j = 0; j < n; j += c) {
        for (int k = 0; k < n; k += c) {
            // some O(1) expressions
        }
    }
}
```

正如你所看到的，这个例子只是二次时间部分例子的延伸。这种情况的最坏时间复杂度是`O(n³)`。

# 多项式时间复杂度类

现在我们已经开始了这个对话，到目前为止我们讨论的大部分时间复杂度类型都是`O(n^k)`类型的，例如，对于`n = 1`，它是常数时间复杂度，而对于`k = 2`，它是二次复杂度。

多项式时间复杂度的概念引导我们进入了一类问题，这些问题是根据其解决方案的复杂性定义的。以下是类别的类型：

+   **P**：任何可以在多项式时间`O(n^k)`内解决的问题。

+   **NP**：任何可以在多项式时间内验证的问题。可以存在可以在非确定性多项式时间内解决的问题（例如数独求解）。如果这些问题的解决方案可以在多项式时间内验证，那么问题被分类为 NP 类问题。NP 类问题是 P 类问题的超集。

+   **NP-Complete**：任何可以在多项式时间内减少为另一个 NP 问题的 NP 问题可以被分类为 NP-Complete 问题。这意味着如果我们知道某个**NP**问题的解决方案，那么可以在多项式时间内推导出另一个 NP 问题的解决方案。

+   **NP-Hard**：如果存在一个可以在多项式时间内减少为**NP-Complete**问题的**NP-Complete**问题，那么问题可以被分类为 NP-Hard 问题（H）。

在大多数现实场景中，我们会遇到很多 P 和 NP 问题，NP 类问题的一个经典例子是旅行推销员问题，其中推销员想要访问`n`个城市，从他的家出发并结束他的旅行。在汽油有限和总里程数有上限的情况下，推销员能否访问所有城市而不用完汽油？

# 递归和加法复杂度

到目前为止，我们已经看到一些相当简单的例子：它们都只有一个循环或嵌套循环。然而，很多时候，会有一些情况需要处理多个循环/函数调用/分支，让我们看一个这种情况下如何计算复杂度的例子？

1.  当我们有连续的循环/函数调用时，我们需要计算每个步骤的个体复杂度，然后将它们相加以获得总体复杂度，如下所示：

```js
            function xyz() {

                abc(); // O(n) operation

                pqr(); // O(log(n)) operation

            }
```

这段代码的综合复杂度将是两个部分复杂度的总和。因此，在这种情况下，总体复杂度将是`O(n + log n)`，渐近地将是`O(n)`。

1.  当我们的函数中有不同时间复杂度的分支时，根据我们所谈论的运行时复杂度的类型，我们需要选择正确的选择：

```js
        function xyz() {

            if (someCondition) {

                abc(); // O(n) operation

            } else {

                pqr(); // O(log(n)) operation

            }

        }
```

在这种情况下，最坏情况的复杂度将由两个分支中较差的那个决定，即`O(n)`，但最佳情况的复杂度将是`O(log(n))`。

1.  递归算法与非递归算法相比有点棘手，因为我们不仅需要确定算法的复杂度，还需要记住递归会触发多少次，因为这将对算法的总体复杂度产生影响，如下面的代码片段所示：

```js
        function rec1(array) {
            // O(1) operations

            if (array.length === 0) return;

            array.pop();

            return rec1(array);
        }
```

虽然我们的方法只执行一些`O(1)`的操作，但它不断改变输入并调用自身，直到输入数组的大小为零。因此，我们的方法最终执行了 n 次，使得总体时间复杂度为`O(n)`。

# 空间复杂度和辅助空间

空间复杂度和辅助空间是在谈论某个算法的空间复杂度时经常混淆和交替使用的术语之一：

+   **辅助空间：**算法暂时占用的额外空间以完成其工作

+   **空间复杂度：**空间复杂度是算法相对于输入大小所占用的总空间加上算法使用的辅助空间。

当我们尝试比较两个算法时，通常会有类似类型的输入，也就是说，输入的大小可以忽略不计，因此我们最终比较的是算法的辅助空间。使用这两个术语没有太大问题，只要我们理解两者之间的区别并正确使用它们。

如果我们使用低级语言如 C，那么我们可以根据数据类型来分解所需/消耗的内存，例如，用 2 个字节来存储整数，4 个字节来存储浮点数等。然而，由于我们使用的是 JavaScript 这种高级语言，情况就不那么简单了，因为我们没有明确区分不同的数据类型。

# 空间复杂度的例子

在谈论算法的空间复杂度时，我们有类似于时间复杂度的类型，如常量空间`S(1)`和线性空间`S(N)`。让我们在下一节中看一些例子。

# 常量空间

常量空间算法是指算法消耗的空间不会因输入的大小或算法的输入参数而改变。

在这一点上，我想重申一下，当我们谈论算法的空间复杂度时，我们谈论的是算法消耗的辅助空间。这意味着即使我们的数组大小为*n*，我们的算法消耗的辅助（或额外）空间将保持不变，如下面的代码片段所示：

```js
function firstElement(arr) {
    return arr[0];
}
```

我们可以看到`firstElement`方法不再占用任何空间，无论输入是什么。因此，我们可以将其表示为空间复杂度`S(1)`。

# 线性空间

线性空间算法是指算法占用的空间量与输入大小成正比的算法，例如，在返回值之前循环遍历数组并将值推送到新数组的算法：

```js
function redundant(array) {
    var result = [];

    for(var i = 0, i < array.size; i++) {
        result.push(array[i]);
    }

    return result;
}
```

如你所见，尽管冗余，我们正在创建一个新数组，并将所有值推送到该数组中，这将占用与输入数组相同的空间。考虑在`push`之前有一个条件的情况，如下面的代码所示：

```js
function notRedundant(array) {
    var result = [];

    for(var i = 0, i < array.size; i++) {
        if (someCondition) {
            result.push(array[i]);
        }
    }

    return result;
}
```

在最坏的情况下，`someCondition` 标志始终为真，并且我们最终得到的结果与输入的大小相同。因此，我们可以断言前面方法的空间复杂度为 `S(n)`。

# 总结

在本章中，我们只是浅尝计算复杂性这个庞然大物。计算复杂性比我们在本章讨论的要多得多。然而，本章讨论的主题和示例是我们大多数人在日常工作中面对的。空间复杂性还有更高级的主题，比如 LSPACE，它是一类可以在对数空间中解决的问题，以及 NLSPACE，它是使用非确定性图灵机的空间量。本章的主要目标是确保我们理解算法的复杂度是如何计算的，以及它如何影响整体输出。在下一章中，我们将讨论我们可以对应用程序进行哪些微观优化，并了解浏览器（主要是 Chrome）的内部工作原理以及我们如何利用它们来改进我们的应用程序。
